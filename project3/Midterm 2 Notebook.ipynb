{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "headed-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, sklearn as skl, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Homework 7\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "height = np.array([[h] for h in height])\n",
    "reg.fit(height, weight)\n",
    "reg.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Homework 8\n",
    "\n",
    "from sklearn import tree\n",
    "## This is a sample of the Baseball Hitters dataset, with X being \"at_bats, hits\" and y being \"walks\"\n",
    "X = [ [293,66], [315,81], [479,130], [496,141], [321,87], [594,169], [185,37], [298,73], [323,81], [401,92], [574,159], [202,53], [418,113], [239,60], [196,43] ]\n",
    "y = [14, 39, 76, 37, 30, 35, 21, 7,  8,  65, 59, 27, 47, 22, 30]\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [A, N, A, N, N, A, N, A, N, A, A, N, N, A, N]\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-marker",
   "metadata": {},
   "source": [
    "### Slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-sociology",
   "metadata": {},
   "source": [
    "NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Tokenize, aka find the terms in, a sentence\n",
    "sentence = \"A wizard is never late, nor is he early. He arrives precisely when he means to.\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "entities = nltk.chunk.ne_chunk( nltk.pos_tag( nltk.word_tokenize(\"\"\"\n",
    "The Shire was divided into four quarters, the Farthings already referred\n",
    "to. North, South, East, and West; and these again each into a number of\n",
    "folklands, which still bore the names of some of the old leading families,\n",
    "although by the time of this history these names were no longer found only in\n",
    "their proper folklands. Nearly all Tooks still lived in the Tookland, but\n",
    "that was not true of many other families, such as the Bagginses or the\n",
    "Boffins. Outside the Farthings were the East and West Marches: the Buckland\n",
    "(see beginning of Chapter V, Book I); and the Westmarch added to the Shire in\n",
    "S.R. 1462.\n",
    "\"\"\")))\n",
    "entities.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-clock",
   "metadata": {},
   "source": [
    "Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytic solution to OLS using Numpy\n",
    "X = [[0,0], [1,1], [2,2]]\n",
    "y = [0, 1, 2]\n",
    "params = np.linalg.solve(X.T.dot(X), X.T.dot(y))\n",
    "\n",
    "from sklearn import linear_model\n",
    "# Solve OLS using Scikit-Learn\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X, y)\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-blind",
   "metadata": {},
   "source": [
    "Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Training data (X, y), T time steps, alpha step\n",
    "def grad_descent(X, y, T, alpha):\n",
    "    m, n = X.shape # m = #examples, n = #features\n",
    "    theta = np.zeros(n) # initialize parameters\n",
    "    f = np.zeros(T) # track loss over time\n",
    "    for i in range(T):\n",
    "        # loss for current parameter vector theta\n",
    "        f[i] = 0.5*np.linalg.norm(X.dot(theta) – y)**2\n",
    "        # compute steepest ascent at f(theta)\n",
    "        g = X.T.dot(X.dot(theta) – y)\n",
    "        # step down the gradient\n",
    "        theta = theta – alpha*g\n",
    "    return theta, f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-signature",
   "metadata": {},
   "source": [
    "LEAST ABSOLUTE DEVIATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(T):\n",
    "# loss for current parameter vector theta\n",
    "f[i] = np.linalg.norm(X.dot(theta) – y, 1)\n",
    "# compute steepest ascent at f(theta)\n",
    "g = X.T.dot( np.sign(X.dot(theta) – y) )\n",
    "# step down the gradient\n",
    "theta = theta – alpha*g\n",
    "return theta, f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-ethnic",
   "metadata": {},
   "source": [
    "# Midterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "corrected-program",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9899494936611665"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,7]\n",
    "b = [0,3]\n",
    "\n",
    "#from scipy import spatial\n",
    "#1 - spatial.distance.cosine(t3, t4)\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "cos_sim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
